{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fytroo/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tuner\n",
    "from tuner.load_data import format_dataset, df_fromdir, train_val_split_df, load_fromdir, load_fromdf\n",
    "from tuner.augment_data import search_condition, augment_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_dir = 'original_dataset/brain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '../examples/micin-dataset/brain/PD061.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1947af6805d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mformat_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../examples/micin-dataset/brain'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./brain'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tuner/load_data.py\u001b[0m in \u001b[0;36mformat_dataset\u001b[0;34m(src_dir, dst_dir, val_size, mode)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mval_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_fromdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tuner/load_data.py\u001b[0m in \u001b[0;36mdf_fromdir\u001b[0;34m(data_dir, columns)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mfname_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '../examples/micin-dataset/brain/PD061.jpg'"
     ]
    }
   ],
   "source": [
    "format_dataset('../examples/micin-dataset/brain', './brain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((246, 3), (20, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_fromdir('brain')\n",
    "\n",
    "df_train, df_val = train_val_split_df(df)\n",
    "df_train.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N     84\n",
       "PS    80\n",
       "PD    51\n",
       "MS    51\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aug_res_file = 'cond.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import json\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import Augmentor\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tuner import utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tuner.load_data import df_fromdir, load_fromdf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import hp\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform, conditional\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tuner import net\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import json\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.datasets import mnist\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import BatchNormalization, Flatten, Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Input, Conv2D, Convolution2D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Activation, concatenate, Dropout\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential, Model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils, to_categorical\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.applications.imagenet_utils import _obtain_input_shape\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'conditional': hp.choice('conditional', [True, False]),\n",
      "        'conditional_1': hp.choice('conditional_1', [True, False]),\n",
      "        'conditional_2': hp.choice('conditional_2', [True, False]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: from keras.utils import to_categorical\n",
      "  3: from tuner.load_data import load_fromdir\n",
      "  4: dataset_dir = 'original_dataset/brain'\n",
      "  5: resize=96\n",
      "  6: x_train, y_train = load_fromdir(os.path.join(dataset_dir, 'train'), resize=resize)\n",
      "  7: x_test, y_test = load_fromdir(os.path.join(dataset_dir, 'validation'), resize=resize)\n",
      "  8: y_train = to_categorical(y_train)\n",
      "  9: y_test = to_categorical(y_test)\n",
      " 10: \n",
      " 11: \n",
      " 12: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     n_out = 4\n",
      "   4:     input_shape = (96, 96, 3)\n",
      "   5:     batch_size = 32\n",
      "   6:     epochs = 10\n",
      "   7:     steps_per_epoch = len(x_train) // batch_size\n",
      "   8: \n",
      "   9:     p = Augmentor.Pipeline()\n",
      "  10: \n",
      "  11:     p.flip_left_right(probability=0.5)\n",
      "  12:     if conditional(space['conditional']):\n",
      "  13:         p.crop_random(probability=1, percentage_area=0.8)\n",
      "  14:         p.resize(probability=1, width=96, height=96)\n",
      "  15:     if conditional(space['conditional_1']):\n",
      "  16:         p.random_erasing(probability=0.5, rectangle_area=0.2)\n",
      "  17:     if conditional(space['conditional_2']):\n",
      "  18:         p.shear(probability=0.3, max_shear_left=2, max_shear_right=2)\n",
      "  19:     print('!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
      "  20:     p.status()\n",
      "  21:     print('!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
      "  22:     g = p.keras_generator_from_array(x_train, y_train, batch_size=batch_size)\n",
      "  23:     g = ((x / 255., y) for (x, y) in g)\n",
      "  24: \n",
      "  25:     inputs = Input(shape=input_shape)\n",
      "  26:     x = inputs\n",
      "  27:     x = Conv2D(32, (3, 3))(x)\n",
      "  28:     x = Conv2D(32, (3, 3))(x)\n",
      "  29:     x = Activation('relu')(x)\n",
      "  30:     x = MaxPooling2D(pool_size=(2, 2))(x)\n",
      "  31:     x = Conv2D(64, (3, 3))(x)\n",
      "  32:     x = Conv2D(64, (3, 3))(x)\n",
      "  33:     x = Activation('relu')(x)\n",
      "  34:     x = MaxPooling2D(pool_size=(2, 2))(x)\n",
      "  35:     x = Dropout(0.25)(x)\n",
      "  36:     x = Flatten()(x)\n",
      "  37:     x = Dense(512)(x)\n",
      "  38:     x = Activation('relu')(x)\n",
      "  39:     x = Dropout(0.5)(x)\n",
      "  40:     x = Dense(n_out)(x)\n",
      "  41:     x = Activation('softmax')(x)\n",
      "  42:     model = Model(inputs=inputs, outputs=x)\n",
      "  43:     model.compile(\n",
      "  44:         loss='categorical_crossentropy',\n",
      "  45:         optimizer=keras.optimizers.rmsprop(lr=0.0001, decay=1e-6),\n",
      "  46:         metrics=['accuracy'])\n",
      "  47: \n",
      "  48:     model.fit_generator(\n",
      "  49:         g,\n",
      "  50:         steps_per_epoch=steps_per_epoch,\n",
      "  51:         validation_data=(x_test, y_test),\n",
      "  52:         epochs=epochs,\n",
      "  53:         verbose=2,\n",
      "  54:     )\n",
      "  55:     score, acc = model.evaluate(x_test, y_test, verbose=0)\n",
      "  56:     print('Test accuracy:', acc)\n",
      "  57:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  58: \n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Operations: 4\n",
      "\t0: Flip (probability=0.5 top_bottom_left_right=LEFT_RIGHT )\n",
      "\t1: CropPercentage (probability=1 percentage_area=0.8 centre=False randomise_percentage_area=False )\n",
      "\t2: Resize (probability=1 width=96 height=96 resample_filter=BICUBIC )\n",
      "\t3: Shear (probability=0.3 max_shear_left=2 max_shear_right=2 )\n",
      "Images: 0\n",
      "Classes: 0\n",
      "\n",
      "You can remove operations using the appropriate index and the remove_operation(index) function.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Epoch 1/10\n",
      " - 3s - loss: 1.4036 - acc: 0.3214 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.3857 - acc: 0.3259 - val_loss: 11.4908 - val_acc: 0.2500\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.3458 - acc: 0.3527 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.3409 - acc: 0.3527 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.3663 - acc: 0.3259 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.3335 - acc: 0.3750 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.3347 - acc: 0.3839 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.3665 - acc: 0.3571 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.3377 - acc: 0.3929 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.3396 - acc: 0.4107 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Test accuracy: 0.25\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Operations: 3\n",
      "\t0: Flip (probability=0.5 top_bottom_left_right=LEFT_RIGHT )\n",
      "\t1: RandomErasing (probability=0.5 rectangle_area=0.2 )\n",
      "\t2: Shear (probability=0.3 max_shear_left=2 max_shear_right=2 )\n",
      "Images: 0\n",
      "Classes: 0\n",
      "\n",
      "You can remove operations using the appropriate index and the remove_operation(index) function.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.4656 - acc: 0.3438 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.3266 - acc: 0.3839 - val_loss: 10.1276 - val_acc: 0.3000\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.3854 - acc: 0.3348 - val_loss: 9.6501 - val_acc: 0.4000\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.3098 - acc: 0.4062 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.2777 - acc: 0.4375 - val_loss: 9.6713 - val_acc: 0.4000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.2040 - acc: 0.5268 - val_loss: 10.6209 - val_acc: 0.3000\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.1741 - acc: 0.5312 - val_loss: 10.1975 - val_acc: 0.3500\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.0819 - acc: 0.5580 - val_loss: 10.9539 - val_acc: 0.3000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.0676 - acc: 0.5982 - val_loss: 7.2532 - val_acc: 0.5500\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.0448 - acc: 0.5982 - val_loss: 8.1752 - val_acc: 0.4500\n",
      "Test accuracy: 0.449999988079\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Operations: 4\n",
      "\t0: Flip (probability=0.5 top_bottom_left_right=LEFT_RIGHT )\n",
      "\t1: CropPercentage (probability=1 percentage_area=0.8 centre=False randomise_percentage_area=False )\n",
      "\t2: Resize (probability=1 width=96 height=96 resample_filter=BICUBIC )\n",
      "\t3: RandomErasing (probability=0.5 rectangle_area=0.2 )\n",
      "Images: 0\n",
      "Classes: 0\n",
      "\n",
      "You can remove operations using the appropriate index and the remove_operation(index) function.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.3647 - acc: 0.3304 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.3624 - acc: 0.3259 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.3557 - acc: 0.3170 - val_loss: 11.9585 - val_acc: 0.2500\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.3766 - acc: 0.3527 - val_loss: 9.5778 - val_acc: 0.3000\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.3642 - acc: 0.3661 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.3503 - acc: 0.3438 - val_loss: 9.8626 - val_acc: 0.2500\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.3508 - acc: 0.3705 - val_loss: 10.4807 - val_acc: 0.3500\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.3769 - acc: 0.3438 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.3290 - acc: 0.3929 - val_loss: 10.4768 - val_acc: 0.3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      " - 0s - loss: 1.3358 - acc: 0.3527 - val_loss: 11.2981 - val_acc: 0.3000\n",
      "Test accuracy: 0.300000011921\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Operations: 1\n",
      "\t0: Flip (probability=0.5 top_bottom_left_right=LEFT_RIGHT )\n",
      "Images: 0\n",
      "Classes: 0\n",
      "\n",
      "You can remove operations using the appropriate index and the remove_operation(index) function.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.4057 - acc: 0.3125 - val_loss: 10.5645 - val_acc: 0.2500\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.3165 - acc: 0.3884 - val_loss: 11.2827 - val_acc: 0.3000\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.2746 - acc: 0.4420 - val_loss: 10.2044 - val_acc: 0.3500\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.1918 - acc: 0.5312 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.0903 - acc: 0.5536 - val_loss: 11.2827 - val_acc: 0.3000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.0218 - acc: 0.5848 - val_loss: 10.3970 - val_acc: 0.3500\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.9720 - acc: 0.6071 - val_loss: 9.6709 - val_acc: 0.4000\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.8912 - acc: 0.6607 - val_loss: 11.1748 - val_acc: 0.3000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.8120 - acc: 0.6875 - val_loss: 10.4768 - val_acc: 0.3500\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.7350 - acc: 0.7321 - val_loss: 8.0600 - val_acc: 0.5000\n",
      "Test accuracy: 0.5\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Operations: 2\n",
      "\t0: Flip (probability=0.5 top_bottom_left_right=LEFT_RIGHT )\n",
      "\t1: RandomErasing (probability=0.5 rectangle_area=0.2 )\n",
      "Images: 0\n",
      "Classes: 0\n",
      "\n",
      "You can remove operations using the appropriate index and the remove_operation(index) function.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Epoch 1/10\n",
      " - 1s - loss: 1.4638 - acc: 0.3036 - val_loss: 9.0997 - val_acc: 0.4000\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.3508 - acc: 0.3616 - val_loss: 10.6904 - val_acc: 0.3000\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.3465 - acc: 0.3705 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2493 - acc: 0.4777 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.1795 - acc: 0.5223 - val_loss: 11.1505 - val_acc: 0.3000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.0786 - acc: 0.5848 - val_loss: 10.4768 - val_acc: 0.3500\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.1038 - acc: 0.5759 - val_loss: 10.4808 - val_acc: 0.3500\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.9828 - acc: 0.6250 - val_loss: 11.2108 - val_acc: 0.3000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.8856 - acc: 0.6875 - val_loss: 9.2256 - val_acc: 0.4000\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.9403 - acc: 0.6250 - val_loss: 9.6815 - val_acc: 0.4000\n",
      "Test accuracy: 0.40000000596\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Operations: 4\n",
      "\t0: Flip (probability=0.5 top_bottom_left_right=LEFT_RIGHT )\n",
      "\t1: CropPercentage (probability=1 percentage_area=0.8 centre=False randomise_percentage_area=False )\n",
      "\t2: Resize (probability=1 width=96 height=96 resample_filter=BICUBIC )\n",
      "\t3: Shear (probability=0.3 max_shear_left=2 max_shear_right=2 )\n",
      "Images: 0\n",
      "Classes: 0\n",
      "\n",
      "You can remove operations using the appropriate index and the remove_operation(index) function.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Epoch 1/10\n",
      " - 1s - loss: 1.4866 - acc: 0.2589 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.3482 - acc: 0.3393 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.3718 - acc: 0.3304 - val_loss: 10.8099 - val_acc: 0.2000\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.3384 - acc: 0.3482 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.3566 - acc: 0.3170 - val_loss: 12.1375 - val_acc: 0.2000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.3409 - acc: 0.3839 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.3279 - acc: 0.3616 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.3184 - acc: 0.3705 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.3437 - acc: 0.3705 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.3446 - acc: 0.3527 - val_loss: 10.6687 - val_acc: 0.2500\n",
      "Test accuracy: 0.25\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Operations: 3\n",
      "\t0: Flip (probability=0.5 top_bottom_left_right=LEFT_RIGHT )\n",
      "\t1: CropPercentage (probability=1 percentage_area=0.8 centre=False randomise_percentage_area=False )\n",
      "\t2: Resize (probability=1 width=96 height=96 resample_filter=BICUBIC )\n",
      "Images: 0\n",
      "Classes: 0\n",
      "\n",
      "You can remove operations using the appropriate index and the remove_operation(index) function.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Epoch 1/10\n",
      " - 1s - loss: 1.4367 - acc: 0.2812 - val_loss: 10.8711 - val_acc: 0.2500\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.3510 - acc: 0.3304 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.3809 - acc: 0.3170 - val_loss: 8.5686 - val_acc: 0.4000\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.3695 - acc: 0.3348 - val_loss: 11.3203 - val_acc: 0.2500\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.3770 - acc: 0.3170 - val_loss: 10.6176 - val_acc: 0.2500\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.3744 - acc: 0.3125 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.3403 - acc: 0.3616 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.3458 - acc: 0.4062 - val_loss: 8.3303 - val_acc: 0.4000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.3635 - acc: 0.3304 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.3248 - acc: 0.3527 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Test accuracy: 0.25\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Operations: 2\n",
      "\t0: Flip (probability=0.5 top_bottom_left_right=LEFT_RIGHT )\n",
      "\t1: Shear (probability=0.3 max_shear_left=2 max_shear_right=2 )\n",
      "Images: 0\n",
      "Classes: 0\n",
      "\n",
      "You can remove operations using the appropriate index and the remove_operation(index) function.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Epoch 1/10\n",
      " - 1s - loss: 1.3738 - acc: 0.3973 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.3190 - acc: 0.3973 - val_loss: 11.4899 - val_acc: 0.2500\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.2655 - acc: 0.4643 - val_loss: 9.0656 - val_acc: 0.3500\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2540 - acc: 0.4152 - val_loss: 6.7682 - val_acc: 0.5000\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.1905 - acc: 0.4821 - val_loss: 8.0591 - val_acc: 0.5000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.1439 - acc: 0.5268 - val_loss: 5.8470 - val_acc: 0.6000\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.0210 - acc: 0.5982 - val_loss: 6.6746 - val_acc: 0.5500\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.9887 - acc: 0.6473 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.0062 - acc: 0.5714 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.0404 - acc: 0.5938 - val_loss: 6.8198 - val_acc: 0.5500\n",
      "Test accuracy: 0.550000011921\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Operations: 2\n",
      "\t0: Flip (probability=0.5 top_bottom_left_right=LEFT_RIGHT )\n",
      "\t1: Shear (probability=0.3 max_shear_left=2 max_shear_right=2 )\n",
      "Images: 0\n",
      "Classes: 0\n",
      "\n",
      "You can remove operations using the appropriate index and the remove_operation(index) function.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Epoch 1/10\n",
      " - 1s - loss: 1.4165 - acc: 0.2768 - val_loss: 9.8268 - val_acc: 0.3500\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.3328 - acc: 0.3839 - val_loss: 10.2545 - val_acc: 0.3000\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.3098 - acc: 0.3973 - val_loss: 8.0830 - val_acc: 0.5000\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2602 - acc: 0.4509 - val_loss: 10.2622 - val_acc: 0.3500\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.2332 - acc: 0.5089 - val_loss: 9.5703 - val_acc: 0.4000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.1448 - acc: 0.5759 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.0584 - acc: 0.6116 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.9791 - acc: 0.6473 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.9393 - acc: 0.6964 - val_loss: 7.2532 - val_acc: 0.5500\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.7883 - acc: 0.7009 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Test accuracy: 0.5\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Operations: 2\n",
      "\t0: Flip (probability=0.5 top_bottom_left_right=LEFT_RIGHT )\n",
      "\t1: RandomErasing (probability=0.5 rectangle_area=0.2 )\n",
      "Images: 0\n",
      "Classes: 0\n",
      "\n",
      "You can remove operations using the appropriate index and the remove_operation(index) function.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Epoch 1/10\n",
      " - 1s - loss: 1.4442 - acc: 0.3304 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.3420 - acc: 0.4330 - val_loss: 8.9616 - val_acc: 0.4000\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.3149 - acc: 0.4018 - val_loss: 8.6953 - val_acc: 0.4500\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2509 - acc: 0.4911 - val_loss: 8.8650 - val_acc: 0.4500\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.1865 - acc: 0.5759 - val_loss: 9.6709 - val_acc: 0.4000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.1378 - acc: 0.5446 - val_loss: 8.0590 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 0s - loss: 1.1252 - acc: 0.5580 - val_loss: 5.8477 - val_acc: 0.6000\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.0031 - acc: 0.6384 - val_loss: 7.2559 - val_acc: 0.5500\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.9661 - acc: 0.5893 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.8249 - acc: 0.7143 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Test accuracy: 0.5\n",
      "cond.json dump.\n"
     ]
    }
   ],
   "source": [
    "def data():\n",
    "    from keras.utils import to_categorical\n",
    "    from tuner.load_data import load_fromdir\n",
    "    dataset_dir = 'original_dataset/brain'\n",
    "    resize=96\n",
    "    x_train, y_train = load_fromdir(os.path.join(dataset_dir, 'train'), resize=resize)\n",
    "    x_test, y_test = load_fromdir(os.path.join(dataset_dir, 'validation'), resize=resize)\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "search_condition(data, aug_res_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing MS83.jpg:   4%|▍         | 9/200 [00:00<00:02, 64.79 Samples/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 46 image(s) found.\n",
      "Output directory set to original_dataset/brain/train/MS/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PD044.jpg:   2%|▎         | 5/200 [00:00<00:05, 34.18 Samples/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 46 image(s) found.\n",
      "Output directory set to original_dataset/brain/train/PD/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing N022.jpg:   9%|▉         | 18/200 [00:00<00:01, 99.92 Samples/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 79 image(s) found.\n",
      "Output directory set to original_dataset/brain/train/N/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PS107.jpg:   2%|▎         | 5/200 [00:00<00:05, 32.97 Samples/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 75 image(s) found.\n",
      "Output directory set to original_dataset/brain/train/PS/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    }
   ],
   "source": [
    "out_dir=os.path.join(dataset_dir, 'auged')\n",
    "if os.path.exists(out_dir):\n",
    "    shutil.rmtree(out_dir)\n",
    "\n",
    "augment_dataset(\n",
    "    src_dir=os.path.join(dataset_dir, 'train'),\n",
    "    out_dir=out_dir,\n",
    "    condition_file=aug_res_file,\n",
    "    sampling_size=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
