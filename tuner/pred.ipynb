{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/fytroo/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Conv2D, Flatten, Dense, GlobalAveragePooling2D\n",
    "\n",
    "from PIL import Image\n",
    "import Augmentor\n",
    "\n",
    "import utils\n",
    "import crud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>validation_table</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>eyes_lenet1</td>\n",
       "      <td>validation_5a260ba0b037cbb5ae741317</td>\n",
       "      <td>5a260aeab037cbb588eafc87</td>\n",
       "      <td>eyes</td>\n",
       "      <td>models/eyes_lenet1.hdf5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>eyes_lenet2</td>\n",
       "      <td>validation_5a260d02b037cbb6d90c3dcd</td>\n",
       "      <td>5a260aeab037cbb588eafc87</td>\n",
       "      <td>eyes</td>\n",
       "      <td>models/eyes_lenet2.hdf5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>eyes_lenet3</td>\n",
       "      <td>validation_5a260dceb037cbb7ca64be27</td>\n",
       "      <td>5a260aeab037cbb588eafc87</td>\n",
       "      <td>eyes</td>\n",
       "      <td>models/eyes_lenet3.hdf5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>eyes_lenet4</td>\n",
       "      <td>validation_5a260e88b037cbb8ada2d955</td>\n",
       "      <td>5a260aeab037cbb588eafc87</td>\n",
       "      <td>eyes</td>\n",
       "      <td>models/eyes_lenet4.hdf5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>brain_lenet1</td>\n",
       "      <td>validation_5a260ebfb037cbb9b1df6d11</td>\n",
       "      <td>5a260aeab037cbb588eafc88</td>\n",
       "      <td>brain</td>\n",
       "      <td>models/brain_lenet1.hdf5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>brain_lenet2</td>\n",
       "      <td>validation_5a260ef4b037cbba424037b0</td>\n",
       "      <td>5a260aeab037cbb588eafc88</td>\n",
       "      <td>brain</td>\n",
       "      <td>models/brain_lenet2.hdf5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>brain_lenet3</td>\n",
       "      <td>validation_5a260f29b037cbbacf7a709d</td>\n",
       "      <td>5a260aeab037cbb588eafc88</td>\n",
       "      <td>brain</td>\n",
       "      <td>models/brain_lenet3.hdf5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>brain_lenet4</td>\n",
       "      <td>validation_5a26106bb037cbbbef355865</td>\n",
       "      <td>5a260aeab037cbb588eafc88</td>\n",
       "      <td>brain</td>\n",
       "      <td>models/brain_lenet4.hdf5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id          name                     validation_table  \\\n",
       "0   1   eyes_lenet1  validation_5a260ba0b037cbb5ae741317   \n",
       "1   2   eyes_lenet2  validation_5a260d02b037cbb6d90c3dcd   \n",
       "2   3   eyes_lenet3  validation_5a260dceb037cbb7ca64be27   \n",
       "3   4   eyes_lenet4  validation_5a260e88b037cbb8ada2d955   \n",
       "4   5  brain_lenet1  validation_5a260ebfb037cbb9b1df6d11   \n",
       "5   6  brain_lenet2  validation_5a260ef4b037cbba424037b0   \n",
       "6   7  brain_lenet3  validation_5a260f29b037cbbacf7a709d   \n",
       "7   8  brain_lenet4  validation_5a26106bb037cbbbef355865   \n",
       "\n",
       "                 dataset_id dataset_name                      path  \n",
       "0  5a260aeab037cbb588eafc87         eyes   models/eyes_lenet1.hdf5  \n",
       "1  5a260aeab037cbb588eafc87         eyes   models/eyes_lenet2.hdf5  \n",
       "2  5a260aeab037cbb588eafc87         eyes   models/eyes_lenet3.hdf5  \n",
       "3  5a260aeab037cbb588eafc87         eyes   models/eyes_lenet4.hdf5  \n",
       "4  5a260aeab037cbb588eafc88        brain  models/brain_lenet1.hdf5  \n",
       "5  5a260aeab037cbb588eafc88        brain  models/brain_lenet2.hdf5  \n",
       "6  5a260aeab037cbb588eafc88        brain  models/brain_lenet3.hdf5  \n",
       "7  5a260aeab037cbb588eafc88        brain  models/brain_lenet4.hdf5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = crud.models()\n",
    "model_df['path'] = ['models/{}.hdf5'.format(name) for name in model_df['name']]\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def try_load_model(model_path):\n",
    "    try:\n",
    "        return load_model(model_path)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "for itr in model_df.iterrows():\n",
    "    model_id = itr[1]['id']\n",
    "    model = try_load_model(itr[1]['path'])\n",
    "    if model:\n",
    "        models.update({\n",
    "            model_id: model\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <keras.models.Sequential at 0x7f1c35dbcf98>,\n",
       " 2: <keras.models.Sequential at 0x7f1c35d716a0>,\n",
       " 3: <keras.models.Sequential at 0x7f1c35b38c50>,\n",
       " 4: <keras.models.Sequential at 0x7f1c2f66df60>,\n",
       " 5: <keras.models.Sequential at 0x7f1c2ec82a58>,\n",
       " 6: <keras.models.Sequential at 0x7f1c2e06fe10>,\n",
       " 7: <keras.models.Sequential at 0x7f1c2dec2400>,\n",
       " 8: <keras.models.Sequential at 0x7f1c2c3a6898>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with sqlite3.connect('curontab.db') as con:\n",
    "    c = con.cursor()\n",
    "    q = '''\n",
    "    update model set dataset_name = 'eyes' where dataset_id= \"5a24a8bab037cb1164d683c2\"\n",
    "    '''#.format(name='brain')\n",
    "    c.execute(q)\n",
    "    con.commit()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with sqlite3.connect('curontab.db') as con:\n",
    "    c = con.cursor()\n",
    "    q = '''\n",
    "    alter table model add column dataset_name[varcher(64)]\n",
    "    '''\n",
    "    c.execute(q)\n",
    "    con.commit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_pred': 'N',\n",
       " 'model_id': 1,\n",
       " 'path': 'dataset/eyes/N/148_0015.JPG',\n",
       " 'pred': 1,\n",
       " 'y_pred': [0.4956947863101959, 0.5043052434921265]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def judge_img_by_data_path(data_path, model_id):\n",
    "    model_info = crud.model_by_id(model_id)\n",
    "    dataset_name = model_info['dataset_name']\n",
    "    label2id = crud.dataset_by_name(dataset_name)['label2id']\n",
    "    id2label = {id:label for label, id in label2id.items()}\n",
    "\n",
    "    model = models[model_id]\n",
    "    batch, h, w, c = model.input_shape\n",
    "    x = utils.img2arr(data_path, resize=(h,w), rescale=1./255)\n",
    "    xs = np.array([x])\n",
    "\n",
    "    y_preds = model.predict(xs)\n",
    "    y_pred = y_preds[0]\n",
    "    pred = y_pred.argmax()\n",
    "    label_pred = id2label[pred]\n",
    "    \n",
    "    res = {\n",
    "        'y_pred': y_pred.tolist(),\n",
    "        'model_id': model_id,\n",
    "        #'dataset_name': dataset_name,\n",
    "        #'label2id': label2id,\n",
    "        #'id2label': id2label,\n",
    "        'path': data_path,\n",
    "        'label_pred': id2label[pred],\n",
    "        'pred': pred,\n",
    "    }\n",
    "    return res\n",
    "#judge_img_by_data_path('dataset/eyes/N/148_0015.JPG', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label_pred': 'N',\n",
       "  'model_id': 2,\n",
       "  'path': 'dataset/eyes/N/148_0015.JPG',\n",
       "  'pred': 1,\n",
       "  'y_pred': [0.12207779288291931, 0.8779221773147583]},\n",
       " {'label_pred': 'AB',\n",
       "  'model_id': 2,\n",
       "  'path': 'dataset/eyes/AB/159_0003.JPG',\n",
       "  'pred': 0,\n",
       "  'y_pred': [0.9999796152114868, 2.035386387433391e-05]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def judge_imgs_by_data_path(data_paths, model_id):\n",
    "    model_info = crud.model_by_id(model_id)\n",
    "    dataset_name = model_info['dataset_name']\n",
    "    label2id = crud.dataset_by_name(dataset_name)['label2id']\n",
    "    id2label = {id:label for label, id in label2id.items()}\n",
    "\n",
    "    model = models[model_id]\n",
    "    batch, h, w, c = model.input_shape\n",
    "    xs = np.array([utils.img2arr(f, resize=(h,w), rescale=1./255) for f in data_paths])\n",
    "\n",
    "    y_preds = model.predict(xs)\n",
    "    df = pd.DataFrame()\n",
    "    df['pred'] = y_preds.argmax(axis=1)\n",
    "    df['label_pred'] = [ id2label[pred] for pred in df['pred']]\n",
    "    df['path'] = data_paths\n",
    "    df['model_id'] = model_id\n",
    "    ds = list(df.T.to_dict().values())\n",
    "    ds\n",
    "\n",
    "    for d, y_pred in zip(ds, y_preds.tolist()):\n",
    "        d.update({'y_pred':y_pred})\n",
    "    res = ds\n",
    "    return res\n",
    "imgs = ['dataset/eyes/N/148_0015.JPG', 'dataset/eyes/AB/159_0003.JPG']\n",
    "#judge_imgs_by_data_path(imgs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def judge_img_by_data_id(data_id, model_id):\n",
    "    data_path = crud.uploaded_data(data_id)['path']\n",
    "    res = judge_img_by_data_path(data_path, model_id)\n",
    "    return res\n",
    "#judge_img_by_data_id(43, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def judge_imgs_by_data_id(data_ids, model_id):\n",
    "    df = crud.uploads_df()\n",
    "    data_paths = df[df['id'].isin(data_ids)]['path'].values.tolist()\n",
    "    res = judge_imgs_by_data_path(data_paths, model_id)\n",
    "    return res\n",
    "#judge_imgs_by_data_id([27,31,35], 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
